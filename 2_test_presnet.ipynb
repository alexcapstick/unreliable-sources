{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Noise with PresNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './outputs/graphs/'\n",
    "results_path = './outputs/presnet_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Baseline Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dicts = []\n",
    "\n",
    "for filename in os.listdir(\n",
    "    os.path.join(\n",
    "        results_path, \"baseline\", \"rrl\",\n",
    "    )\n",
    "):\n",
    "    if filename.endswith('.json'):\n",
    "        with open(\n",
    "            os.path.join(\n",
    "                results_path, \"baseline\", \"rrl\", filename\n",
    "            )\n",
    "        ) as f:\n",
    "            results_dicts.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results_dict in results_dicts:\n",
    "    for dataset in results_dict:\n",
    "        if dataset not in results:\n",
    "            results[dataset] = {}\n",
    "        for corruption_type in results_dict[dataset]:\n",
    "            if corruption_type not in results[dataset]:\n",
    "                results[dataset][corruption_type] = {}\n",
    "            for run in results_dict[dataset][corruption_type]:\n",
    "                if int(run) in results[dataset][corruption_type]:\n",
    "                    new_run = int(max(results[dataset][corruption_type].keys())) + 1\n",
    "                    results[dataset][corruption_type][new_run] = results_dict[dataset][corruption_type][run]\n",
    "                else:\n",
    "                    results[dataset][corruption_type][int(run)] = results_dict[dataset][corruption_type][run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baseline = []\n",
    "\n",
    "for dataset in results:\n",
    "    for corruption_type in results[dataset]:\n",
    "        for run in results[dataset][corruption_type]:\n",
    "            results_baseline.append(\n",
    "                pd.json_normalize(\n",
    "                    results[dataset][corruption_type][run]['test_acc']\n",
    "                ).assign(\n",
    "                    dataset=dataset,\n",
    "                    corruption_type=corruption_type,\n",
    "                    run=run\n",
    "                )\n",
    "                .assign(epoch=lambda x: x['epoch']+2)\n",
    "            )\n",
    "results_baseline = pd.concat(results_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting LAP results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dicts = []\n",
    "\n",
    "for filename in os.listdir(\n",
    "    os.path.join(\n",
    "        results_path,\n",
    "    )\n",
    "):\n",
    "    if filename.endswith('.json'):\n",
    "        with open(\n",
    "            os.path.join(\n",
    "                results_path, filename\n",
    "            )\n",
    "        ) as f:\n",
    "            results_dicts.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results_dict in results_dicts:\n",
    "    for dataset in results_dict:\n",
    "        if dataset not in results:\n",
    "            results[dataset] = {}\n",
    "        for corruption_type in results_dict[dataset]:\n",
    "            if corruption_type not in results[dataset]:\n",
    "                results[dataset][corruption_type] = {}\n",
    "            for run in results_dict[dataset][corruption_type]:\n",
    "                new_run = int(run)\n",
    "                if int(run) in results[dataset][corruption_type]:\n",
    "                    new_run = int(max(results[dataset][corruption_type].keys())) + 1\n",
    "                results[dataset][corruption_type][new_run] = [\n",
    "                    dict(epoch=int(epoch), **metrics) \n",
    "                    for epoch, metrics in results_dict[dataset][corruption_type][run].items() \n",
    "                    if epoch != 'corrupt_sources'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lap = []\n",
    "\n",
    "for dataset in results:\n",
    "    for corruption_type in results[dataset]:\n",
    "        for run in results[dataset][corruption_type]:\n",
    "            results_lap.append(\n",
    "                pd.json_normalize(\n",
    "                    results[dataset][corruption_type][run]\n",
    "                )\n",
    "                .assign(\n",
    "                    dataset=dataset,\n",
    "                    corruption_type=corruption_type,\n",
    "                    run=run\n",
    "                )\n",
    "                .assign(epoch=lambda x: x['epoch']+1)\n",
    "            )\n",
    "results_lap = pd.concat(results_lap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_epochs = pd.concat(\n",
    "    [\n",
    "        (\n",
    "            results_lap\n",
    "            .reset_index()\n",
    "            .assign(method='lap')\n",
    "        ),\n",
    "        (\n",
    "            results_baseline\n",
    "            .reset_index()\n",
    "            .rename(columns={'value.top1': 'test_top1acc'})\n",
    "            .assign(method='baseline')\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all = pd.concat(\n",
    "    [\n",
    "        (\n",
    "            results_lap\n",
    "            .groupby(['dataset', 'corruption_type', 'run',])\n",
    "            .agg({'test_top1acc': 'max'})\n",
    "            .sort_values('test_top1acc', ascending=False)\n",
    "            .reset_index()\n",
    "            .assign(method='lap')\n",
    "        ),\n",
    "        (\n",
    "            results_baseline\n",
    "            .groupby(['dataset', 'corruption_type', 'run',])\n",
    "            .agg({'value.top1': 'max'})\n",
    "            .reset_index()\n",
    "            .rename(columns={'value.top1': 'test_top1acc'})\n",
    "            .assign(method='baseline')\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corruption Type</th>\n",
       "      <th>RRL</th>\n",
       "      <th>RRL + LAP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original Data</td>\n",
       "      <td>\\textbf{87.67 ± 0.37}</td>\n",
       "      <td>\\textbf{87.54 ± 0.22}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chunk Shuffle</td>\n",
       "      <td>82.93 ± 0.29</td>\n",
       "      <td>\\textbf{84.27 ± 0.31}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Label</td>\n",
       "      <td>76.04 ± 1.43</td>\n",
       "      <td>\\textbf{80.31 ± 0.58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Batch Label Shuffle</td>\n",
       "      <td>77.66 ± 0.71</td>\n",
       "      <td>\\textbf{80.84 ± 0.51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Batch Label Flip</td>\n",
       "      <td>78.81 ± 0.66</td>\n",
       "      <td>\\textbf{82.02 ± 0.45}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Added Noise</td>\n",
       "      <td>78.51 ± 0.74</td>\n",
       "      <td>\\textbf{81.70 ± 0.48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Replace With Noise</td>\n",
       "      <td>\\textbf{80.05 ± 0.65}</td>\n",
       "      <td>79.00 ± 0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Corruption Type                    RRL              RRL + LAP\n",
       "0        Original Data  \\textbf{87.67 ± 0.37}  \\textbf{87.54 ± 0.22}\n",
       "1        Chunk Shuffle           82.93 ± 0.29  \\textbf{84.27 ± 0.31}\n",
       "2         Random Label           76.04 ± 1.43  \\textbf{80.31 ± 0.58}\n",
       "3  Batch Label Shuffle           77.66 ± 0.71  \\textbf{80.84 ± 0.51}\n",
       "4     Batch Label Flip           78.81 ± 0.66  \\textbf{82.02 ± 0.45}\n",
       "5          Added Noise           78.51 ± 0.74  \\textbf{81.70 ± 0.48}\n",
       "6   Replace With Noise  \\textbf{80.05 ± 0.65}           79.00 ± 0.75"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bold_max_value(x, model_names):\n",
    "    x = x.copy()\n",
    "    len_cols = x.shape[0]\n",
    "    n_models = len(model_names)\n",
    "    idx_bold = (\n",
    "        x\n",
    "        [-n_models:]\n",
    "        .str.replace(\" \", \"\")\n",
    "        .str.split(\"±\")\n",
    "        .str[0]\n",
    "        .astype(float)\n",
    "        .argmax()\n",
    "    )\n",
    "    max_val = x.iloc[idx_bold+len_cols-n_models]\n",
    "    max_val, max_std = map(float, max_val.split(\"±\"))\n",
    "\n",
    "    for i in range(len_cols-n_models, len_cols):\n",
    "        val = x.iloc[i]\n",
    "        val, std = map(float, val.split(\"±\"))\n",
    "        if val >= max_val - max_std and val <= max_val + max_std:\n",
    "            x.iloc[i] = '\\\\textbf{' + x.iloc[i] + '}'\n",
    "    \n",
    "    return x\n",
    "\n",
    "experiment_dict = {\n",
    "    'no_c': 'Original Data',\n",
    "    'c_cs': 'Chunk Shuffle',\n",
    "    'c_rl': 'Random Label',\n",
    "    'c_lbs': 'Batch Label Shuffle',\n",
    "    'c_lbf': 'Batch Label Flip',\n",
    "    'c_ns': 'Added Noise',\n",
    "    'c_no': 'Replace With Noise',\n",
    "}\n",
    "\n",
    "dataset_dict = {\n",
    "    'cifar10': 'CIFAR-10',\n",
    "    'cifar100': 'CIFAR-100',\n",
    "    'fmnist': 'F-MNIST'\n",
    "}\n",
    "\n",
    "\n",
    "model_names = [\n",
    "    'RRL',\n",
    "    'RRL + LAP',\n",
    "]\n",
    "\n",
    "corruption_type_order = [\n",
    "    'Original Data',\n",
    "    'Chunk Shuffle',\n",
    "    'Random Label',\n",
    "    'Batch Label Shuffle',\n",
    "    'Batch Label Flip',\n",
    "    'Added Noise',\n",
    "    'Replace With Noise',\n",
    "]\n",
    "\n",
    "dataset_order = [\n",
    "    'CIFAR-10'\n",
    "]\n",
    "\n",
    "\n",
    "results_formatted = (\n",
    "    results_all\n",
    "    .replace(\n",
    "        {\n",
    "            'dataset': dataset_dict,\n",
    "            'corruption_type': experiment_dict\n",
    "        }\n",
    "    )\n",
    "    .assign(\n",
    "        method=lambda x: x['method'].map({'lap': 'RRL + LAP', 'baseline': 'RRL'})\n",
    "    )\n",
    "    .drop(\n",
    "        columns=['run']\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            'dataset': 'Dataset',\n",
    "            'corruption_type': 'Corruption Type',\n",
    "            'test_top1acc': 'Accuracy (%)',\n",
    "            'method': 'Model Name'\n",
    "        }\n",
    "    )\n",
    "    .assign(\n",
    "        **{\n",
    "            'Accuracy (%)': lambda x: x['Accuracy (%)']*100\n",
    "        }\n",
    "    )\n",
    "    .loc[lambda x: x[\"Model Name\"].isin(model_names)]\n",
    "    .groupby(['Dataset', 'Corruption Type', 'Model Name'])\n",
    "    .agg(['mean', 'std'])\n",
    "    .assign(result = (\n",
    "        lambda x: \n",
    "        x['Accuracy (%)']['mean'].map('{:.2f}'.format)\n",
    "        + ' ± ' \n",
    "        + x['Accuracy (%)']['std'].map('{:.2f}'.format)\n",
    "    ))\n",
    "    ['result']\n",
    "    .unstack(level='Model Name')\n",
    "    .reindex(\n",
    "        [\n",
    "            (ds, ct)  for ds in dataset_order for ct in corruption_type_order\n",
    "        ]\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename_axis(index=None, columns=None)\n",
    "    [\n",
    "        ['Dataset', 'Corruption Type'] + model_names\n",
    "    ]\n",
    "    .apply(\n",
    "        bold_max_value,\n",
    "        model_names = model_names,\n",
    "        axis=1\n",
    "    )\n",
    "    .drop(\n",
    "        columns=['Dataset']\n",
    "    )\n",
    ")\n",
    "results_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "Corruption Type & RRL & RRL + LAP \\\\\n",
      "\\midrule\n",
      "Original Data & \\textbf{87.67 ± 0.37} & \\textbf{87.54 ± 0.22} \\\\\n",
      "Chunk Shuffle & 82.93 ± 0.29 & \\textbf{84.27 ± 0.31} \\\\\n",
      "Random Label & 76.04 ± 1.43 & \\textbf{80.31 ± 0.58} \\\\\n",
      "Batch Label Shuffle & 77.66 ± 0.71 & \\textbf{80.84 ± 0.51} \\\\\n",
      "Batch Label Flip & 78.81 ± 0.66 & \\textbf{82.02 ± 0.45} \\\\\n",
      "Added Noise & 78.51 ± 0.74 & \\textbf{81.70 ± 0.48} \\\\\n",
      "Replace With Noise & \\textbf{80.05 ± 0.65} & 79.00 ± 0.75 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_formatted.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
